{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 5: Image search using CLIP\n",
    "\n",
    "## Overview\n",
    "1. The code will run encode all pictures in `datasetFolder_path` into embeddings by `openai-CLIP` pre-trained model\n",
    "2. Embeddings are store in vectors using `faiss` \n",
    "3. The user interface will receive an input image, encode it, and search for similar image in the dataset using `faiss`\n",
    "4. The dataset image that have the highest similarity score will be shown on the output box.\n",
    "## Before running the code\n",
    "\n",
    "1. find the image that is not include in the dataset to test the recommendation algorithm.\n",
    "\n",
    "## Libraries\n",
    "1. `torch ftfy regex tqdm` as prerequisite for `openai-clip`\n",
    "2. `openai-clip` as pre-trained model\n",
    "3. `numpy` for array manipulation\n",
    "4. `gradio` for mockup user interface\n",
    "5. `faiss-cpu` for storing embeddings in vector, search algorithm (for running on cpu)\n",
    "6. `gdown` for downloading folder shared on google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up workspace for manually selected dataset\n",
    "If you want to create your own dataset, please follow this guideline,\n",
    "1. Create an empty folder with the name of `selected_images`\n",
    "2. In the workspace, the directory should be in this hierachy\n",
    "\n",
    "```\n",
    "Workspace Folder\n",
    "|--/selected_images/\n",
    "    |---image_01.jpg\n",
    "    |---image_02.jpg\n",
    "    |---image_nn.jpg \n",
    "|-- 05_CLIP_image_search.ipynb\n",
    "```\n",
    "\n",
    "3. uncomment `datasetFolder_path = os.getcwd() + '/selected_images/'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: ftfy in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (6.1.1)\n",
      "Requirement already satisfied: regex in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (2023.8.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from ftfy) (0.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: openai-clip in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: ftfy in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from openai-clip) (6.1.1)\n",
      "Requirement already satisfied: regex in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from openai-clip) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from openai-clip) (4.66.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from ftfy->openai-clip) (0.2.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from tqdm->openai-clip) (0.4.6)\n",
      "Requirement already satisfied: gradio in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (3.41.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (5.1.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (0.103.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.5.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (0.16.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (1.24.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (3.9.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (2.1.0)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (10.0.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (1.10.12)\n",
      "Requirement already satisfied: pydub in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: requests~=2.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (2.31.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (4.5.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (0.23.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from gradio-client==0.5.0->gradio) (2023.6.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from requests~=2.0->gradio) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from requests~=2.0->gradio) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from requests~=2.0->gradio) (2023.7.22)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from httpx->gradio) (0.17.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (4.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\wisar\\.virtualenvs\\lab1-xxqfwi6-\\lib\\site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.3)\n"
     ]
    }
   ],
   "source": [
    "# install library\n",
    "\n",
    "! pip install torch ftfy regex tqdm numpy\n",
    "! pip install openai-clip\n",
    "! pip install gradio\n",
    "! pip install faiss-cpu\n",
    "! pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import essential library\n",
    "\n",
    "import clip\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set running device to cpu\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see openai-clip available pre-train model\n",
    "\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Vit-B/32 model\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pre-select dataset from shared google drive\n",
    "\n",
    "import gdown\n",
    "\n",
    "url = \"https://drive.google.com/drive/folders/1eFmm2TUrsPUzPWRP_sE3CnJc6g-La3rC?usp=drive_link\"\n",
    "gdown.download_folder(url, use_cookies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "datasetFolder_path = os.getcwd() + '/HM_sample_dataset/' # pre-selected dataset\n",
    "# datasetFolder_path = os.getcwd() + '/selected_images/' # manually create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all filename in dataset folder\n",
    "\n",
    "imageFilename_list = os.listdir(datasetFolder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings vector using FAISS\n",
    "\n",
    "index = faiss.IndexFlatL2(512) # dimension of 1 embedding decoded from CLIP model is 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  5.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# encode dataset\n",
    "datasetEmbeddings_list = []\n",
    "\n",
    "for imageFilename in tqdm(imageFilename_list):\n",
    "    with torch.no_grad():\n",
    "        image = preprocess(Image.open(datasetFolder_path + imageFilename)).unsqueeze(0).to(device)\n",
    "        datasetEmbeddings_list.append(model.encode_image(image).numpy(force=True)[0].astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add embeddings into faiss vector\n",
    "\n",
    "datasetEmbeddings_npArray = np.array(datasetEmbeddings_list) # change to numpy array for FAISS \n",
    "index.add(datasetEmbeddings_npArray)\n",
    "\n",
    "print(index.ntotal) # number of images embeddings store in dataset vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def recommend_similar_image(imageFile_path):\n",
    "    print(f\"get image path {imageFile_path}\")\n",
    "\n",
    "    test_image = preprocess(Image.open(imageFile_path)).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_embeddings = model.encode_image(test_image).numpy(force=True)[0].astype('float32')\n",
    "        test_embeddings = np.array([test_embeddings])\n",
    "\n",
    "    recommend_number = 4 # number of recommendations\n",
    "    square_distance, image_index = index.search(test_embeddings,k)\n",
    "    print(image_index)\n",
    "    print(square_distance)\n",
    "    \n",
    "    print(\"Opening Images...\")\n",
    "    recommended_images_list = [(Image.open(datasetFolder_path + imageFilename_list[image_index[0][i]]), f\"Recommended Rank {i+1}\") for i in range(recommend_number)]\n",
    "    return recommended_images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    fn=recommend_similar_image,\n",
    "    inputs=gr.Image(type=\"filepath\"),\n",
    "    outputs= gr.Gallery(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAB1-XXQFwi6-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
